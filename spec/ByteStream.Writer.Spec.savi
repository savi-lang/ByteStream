:class ByteStream.Writer.Spec
  :is Spec
  :const describes: "ByteStream.Writer"

  :it "writes chunks of bytes and individual bytes"
    streams = ByteStream.Pair.new, read = streams.read, write = streams.write

    // Write some data.
    write << b"Hello"
    write.push(',').push(' ')
    write << b"World"
    write.push('!')

    // Nothing is actually written until flush.
    assert: read.bytes_ahead == 0
    assert no_error: write.flush!
    assert: read.bytes_ahead == 13

    // After flush, now the data can be read.
    assert: read.extract_all == b"Hello, World!"

  :it "writes U16, U32, and U64 values in native byte order"
    streams = ByteStream.Pair.new, read = streams.read, write = streams.write

    // Write some data.
    write.push_native_u16(0x0123)
    write.push_native_u16(0x4567)
    write.push_native_u32(0x01234567)
    write.push_native_u32(0x89ABCDEF)
    write.push_native_u64(0x012345678899AABB)
    write.push_native_u64(0xCCDDEEFF76543210)

    // Nothing is actually written until flush.
    assert: read.bytes_ahead == 0
    assert no_error: write.flush!
    assert: read.bytes_ahead == 28

    // After flush, now the data can be read.
    assert: read.take_native_u16! == 0x0123
    assert: read.take_native_u16! == 0x4567
    assert: read.take_native_u32! == 0x01234567
    assert: read.take_native_u32! == 0x89ABCDEF
    assert: read.take_native_u64! == 0x012345678899AABB
    assert: read.take_native_u64! == 0xCCDDEEFF76543210

  :it "efficiently groups individual bytes in the same chunk prior to flush"
    chunks = []
    write = ByteStream.Writer.new(_SinkToArray.new(chunks))

    write.push('A').push('B').push('C')
    assert no_error: write.flush!
    assert: chunks == [b"ABC"]

    write.push('1').push('2').push('3')
    assert no_error: write.flush!
    assert: chunks == [b"ABC", b"123"]

  :it "efficiently groups small chunks in the same chunk prior to flush"
    chunks = []
    write = ByteStream.Writer.new(_SinkToArray.new(chunks))

    b_64 = b"0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
    b_65 = b"0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef!"

    // 64 bytes is small enough to just copy into the "current chunk",
    // but 65 bytes will always end the current chunk and start a new one.
    write << b_64
    write << b_64
    write.push('.')
    write << b_64
    write << b_65
    write.push('.')
    write << b_64
    write << b_65
    write << b_64
    write.push('.')
    assert no_error: write.flush!
    assert: chunks == [
      Bytes.join([b_64, b_64, b".", b_64])
      b_65
      Bytes.join([b".", b_64])
      b_65
      Bytes.join([b_64, b"."])
    ]

    // Each later grouped chunk will be allocated with enough space to fit the
    // largest prior grouped chunk (in this example, the first one was largest).
    assert: chunks[2]!.space == chunks[0]!.space
    assert: chunks[4]!.space == chunks[0]!.space

:: This utility class is used in testing to capture the array of chunks written,
:: so that we can test where exactly the chunk boundaries end up being laid.
:class _SinkToArray
  :is ByteStream.Sink
  :let array Array(Bytes)
  :new (@array)

  :fun ref write_bytes(bytes Bytes'val): @array << bytes, @
  :fun ref write_flush!: @
